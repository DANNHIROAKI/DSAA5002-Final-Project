{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - Debug Prototype",
    "",
    "Fast, end-to-end smoke tests for clustering and downstream response modeling on a small sample. This notebook mirrors the experiment scripts with lighter settings to validate data flow and metric calculations."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "PROJECT_ROOT = Path(__file__).resolve().parents[1]\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.append(str(PROJECT_ROOT))\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "from customer_segmentation.src.data.load import load_raw_data\n",
    "from customer_segmentation.src.data.preprocess import clean_data\n",
    "from customer_segmentation.src.data.features import assemble_feature_table\n",
    "from customer_segmentation.src.models.kmeans_baseline import run_kmeans\n",
    "from customer_segmentation.src.models.gmm_baseline import run_gmm\n",
    "from customer_segmentation.src.models.rajc import RAJCConfig, RAJCModel\n",
    "from customer_segmentation.src.utils.seed_utils import seed_everything\n",
    "from customer_segmentation.src.utils.metrics_utils import response_rate_by_cluster, classification_summary\n",
    "\n",
    "seed_everything(42)\n",
    "DATA_DIR = PROJECT_ROOT / \"data\" / \"raw\"\n",
    "CSV_NAME = \"marketing_campaign.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "try:\n",
    "    raw_df = load_raw_data(DATA_DIR, filename=CSV_NAME, parse_dates=[\"Dt_Customer\"])\n",
    "    cleaned_df = clean_data(raw_df)\n",
    "    print(f\"Loaded and cleaned: {cleaned_df.shape}\")\n",
    "except FileNotFoundError as exc:\n",
    "    print(exc)\n",
    "    cleaned_df = pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature assembly and quick train/val split",
    "The engineered feature table matches the experiment scripts; we keep a small hold-out for downstream checks."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "if not cleaned_df.empty:\n",
    "    features_df, labels, transformer = assemble_feature_table(cleaned_df)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        features_df, labels, test_size=0.2, random_state=42, stratify=labels\n",
    "    )\n",
    "    print(f\"Features: {features_df.shape}, train: {X_train.shape}, val: {X_val.shape}\")\n",
    "else:\n",
    "    features_df = pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline clustering sanity checks",
    "Run lightweight K-Means and GMM on the full feature set and inspect response heterogeneity per cluster."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "if not features_df.empty:\n",
    "    km_model, km_labels = run_kmeans(features_df, n_clusters=4, random_state=42)\n",
    "    print(f\"K-Means inertia: {km_model.inertia():.2f}\")\n",
    "    print(response_rate_by_cluster(km_labels, labels))\n",
    "\n",
    "    gmm_model, gmm_labels = run_gmm(features_df, n_components=4, random_state=42)\n",
    "    print(response_rate_by_cluster(gmm_labels, labels))\n",
    "else:\n",
    "    print(\"No features available; skipping clustering checks.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAJC small run",
    "A brief alternating optimization pass to validate the joint objective wiring."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "if not features_df.empty:\n",
    "    config = RAJCConfig(n_clusters=4, lambda_response=0.5, max_iter=5, random_state=42)\n",
    "    rajc = RAJCModel(config=config)\n",
    "    rajc.fit(features_df, labels)\n",
    "    rajc_labels = rajc.predict(features_df)\n",
    "    print(response_rate_by_cluster(rajc_labels, labels))\n",
    "else:\n",
    "    print(\"No features available; skipping RAJC run.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downstream logistic regression",
    "Compare base features vs. RAJC cluster IDs concatenated as additional signals."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "if not features_df.empty:\n",
    "    def evaluate_with_extra_clusters(cluster_labels=None):\n",
    "        X_train_use, X_val_use = X_train.copy(), X_val.copy()\n",
    "        if cluster_labels is not None:\n",
    "            cluster_dummies = pd.get_dummies(cluster_labels, prefix=\"cluster\")\n",
    "            X_full = pd.concat([features_df, cluster_dummies], axis=1)\n",
    "            X_train_use = X_full.loc[X_train.index]\n",
    "            X_val_use = X_full.loc[X_val.index]\n",
    "\n",
    "        clf = LogisticRegression(max_iter=200)\n",
    "        clf.fit(X_train_use, y_train)\n",
    "        val_proba = pd.Series(clf.predict_proba(X_val_use)[:, 1], index=X_val.index)\n",
    "        return classification_summary(y_val, val_proba, top_fracs=(0.1, 0.2, 0.3))\n",
    "\n",
    "    print(\"Base only:\")\n",
    "    display(evaluate_with_extra_clusters())\n",
    "\n",
    "    print(\"+ RAJC clusters:\")\n",
    "    display(evaluate_with_extra_clusters(rajc_labels if not features_df.empty else None))\n",
    "else:\n",
    "    print(\"No features available; skipping downstream logistic regression.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
